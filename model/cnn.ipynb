{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in os.listdir(data_path):\n",
    "    if os.path.isdir(os.path.join(data_path, path)):\n",
    "        print(os.path.join(data_path, path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = os.path.join(data_path, 'train')\n",
    "test_data_path = os.path.join(data_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = dict()\n",
    "\n",
    "for path in sorted(os.listdir(train_data_path)):\n",
    "    if os.path.isdir(os.path.join(train_data_path, path)):\n",
    "        train_classes.setdefault(len(train_classes), path)\n",
    "        \n",
    "train_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classes = dict()\n",
    "\n",
    "for path in sorted(os.listdir(test_data_path)):\n",
    "    if os.path.isdir(os.path.join(test_data_path, path)):\n",
    "        test_classes.setdefault(len(test_classes), path)\n",
    "        \n",
    "test_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1070'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = T.Compose([\n",
    "    T.Resize((256,256)),\n",
    "    T.CenterCrop(224),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transform = T.Compose([\n",
    "    T.Resize((256,256)),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(\n",
    "    root=train_data_path,\n",
    "    transform=train_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 750\n",
       "    Root location: ../dataset/train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(256, 256), interpolation=PIL.Image.BILINEAR)\n",
       "               CenterCrop(size=(224, 224))\n",
       "               RandomHorizontalFlip(p=0.5)\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "           )"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ImageFolder(\n",
    "    root=test_data_path,\n",
    "    transform=val_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 2500\n",
       "    Root location: ../dataset/test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(256, 256), interpolation=PIL.Image.BILINEAR)\n",
       "               CenterCrop(size=(224, 224))\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "           )"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=0,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=0,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47, 157)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoodNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FoodNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 8, 3)\n",
    "        self.conv3 = nn.Conv2d(8, 16, 3)\n",
    "        self.drop = nn.Dropout(.1)\n",
    "        self.fc1 = nn.Linear(BATCH_SIZE * 26 * 26, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, BATCH_SIZE * 26 * 26)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.drop(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FoodNet()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = {\n",
    "    'train': train_loader,\n",
    "    'val': test_loader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/25\n",
      "=========================\n",
      "Loss (train): 2.2924972645779875, Acc (train): 0.12310030422312149\n",
      "Loss (val): 2.9416618590142316, Acc (val): 0.2056414923470491\n",
      "\n",
      "Epoch 2/25\n",
      "=========================\n",
      "Loss (train): 2.196672977285182, Acc (train): 0.19604863258118324\n",
      "Loss (val): 2.8330668453957624, Acc (val): 0.265696087460609\n",
      "\n",
      "Epoch 3/25\n",
      "=========================\n",
      "Loss (train): 2.080033233825197, Acc (train): 0.2393617021276596\n",
      "Loss (val): 2.71517841299628, Acc (val): 0.31488853503184716\n",
      "\n",
      "Epoch 4/25\n",
      "=========================\n",
      "Loss (train): 1.9721416945153094, Acc (train): 0.28495440743070966\n",
      "Loss (val): 2.695035883575488, Acc (val): 0.3197793448996392\n",
      "\n",
      "Epoch 5/25\n",
      "=========================\n",
      "Loss (train): 1.9032925925356277, Acc (train): 0.31876899714165546\n",
      "Loss (val): 2.704692455613689, Acc (val): 0.3243289354500497\n",
      "\n",
      "Epoch 6/25\n",
      "=========================\n",
      "Loss (train): 1.8154431023496262, Acc (train): 0.36094224960245985\n",
      "Loss (val): 2.70630016220603, Acc (val): 0.36720882631411217\n",
      "\n",
      "Epoch 7/25\n",
      "=========================\n",
      "Loss (train): 1.5839562086348837, Acc (train): 0.44110942267357034\n",
      "Loss (val): 2.7578935824382076, Acc (val): 0.3617493176156548\n",
      "\n",
      "Epoch 8/25\n",
      "=========================\n",
      "Loss (train): 1.3650247771689232, Acc (train): 0.5302051673544214\n",
      "Loss (val): 2.8393930568816557, Acc (val): 0.4063353048768013\n",
      "\n",
      "Epoch 9/25\n",
      "=========================\n",
      "Loss (train): 1.0834460638939065, Acc (train): 0.6610942254675195\n",
      "Loss (val): 2.9248627598877923, Acc (val): 0.43556642418454405\n",
      "\n",
      "Epoch 10/25\n",
      "=========================\n",
      "Loss (train): 0.9443430076254175, Acc (train): 0.6709726452827454\n",
      "Loss (val): 2.884240171332268, Acc (val): 0.42737716132668174\n",
      "\n",
      "Epoch 11/25\n",
      "=========================\n",
      "Loss (train): 0.7616299454202043, Acc (train): 0.7518996964109704\n",
      "Loss (val): 3.4794144102722218, Acc (val): 0.4420495906453224\n",
      "\n",
      "Epoch 12/25\n",
      "=========================\n",
      "Loss (train): 0.5638914507754306, Acc (train): 0.8109802438857707\n",
      "Loss (val): 3.4006580997044873, Acc (val): 0.47008644243714154\n",
      "\n",
      "Epoch 13/25\n",
      "=========================\n",
      "Loss (train): 0.5321880877017975, Acc (train): 0.8303571432194812\n",
      "Loss (val): 3.753421394498485, Acc (val): 0.4535941766325835\n",
      "\n",
      "Epoch 14/25\n",
      "=========================\n",
      "Loss (train): 0.3788144047907058, Acc (train): 0.8879179345800522\n",
      "Loss (val): 3.882901076061331, Acc (val): 0.482768426275557\n",
      "\n",
      "Epoch 15/25\n",
      "=========================\n",
      "Loss (train): 0.28659948627365395, Acc (train): 0.9156534963465751\n",
      "Loss (val): 4.317819457857093, Acc (val): 0.4942561422184015\n",
      "\n",
      "Epoch 16/25\n",
      "=========================\n",
      "Loss (train): 0.2524758868632799, Acc (train): 0.9223024325167879\n",
      "Loss (val): 4.49726409174407, Acc (val): 0.49664467725024863\n",
      "\n",
      "Epoch 17/25\n",
      "=========================\n",
      "Loss (train): 0.17510054203027742, Acc (train): 0.943958967290026\n",
      "Loss (val): 4.880553914453526, Acc (val): 0.5011373978511543\n",
      "\n",
      "Epoch 18/25\n",
      "=========================\n",
      "Loss (train): 0.1326634646888743, Acc (train): 0.9627659574468085\n",
      "Loss (val): 5.674007173295424, Acc (val): 0.49721337579617836\n",
      "\n",
      "Epoch 19/25\n",
      "=========================\n",
      "Loss (train): 0.16016335429702985, Acc (train): 0.9530775090481373\n",
      "Loss (val): 5.216444274401708, Acc (val): 0.4967015472946653\n",
      "\n",
      "Epoch 20/25\n",
      "=========================\n",
      "Loss (train): 0.1425088671372926, Acc (train): 0.9561170212765957\n",
      "Loss (val): 5.22156199610015, Acc (val): 0.49442675159235666\n",
      "\n",
      "Epoch 21/25\n",
      "=========================\n",
      "Loss (train): 0.08990178903208133, Acc (train): 0.9718844992049197\n",
      "Loss (val): 5.250201458182589, Acc (val): 0.4943698819275874\n",
      "\n",
      "Epoch 22/25\n",
      "=========================\n",
      "Loss (train): 0.12063640342193081, Acc (train): 0.9627659574468085\n",
      "Loss (val): 5.549911832691995, Acc (val): 0.5103503184713376\n",
      "\n",
      "Epoch 23/25\n",
      "=========================\n",
      "Loss (train): 0.08962065912783146, Acc (train): 0.973404255319149\n",
      "Loss (val): 5.488423275470638, Acc (val): 0.4964171974522293\n",
      "\n",
      "Epoch 24/25\n",
      "=========================\n",
      "Loss (train): 0.12849848199774452, Acc (train): 0.9574468085106383\n",
      "Loss (val): 5.970172950053279, Acc (val): 0.47571656050955413\n",
      "\n",
      "Epoch 25/25\n",
      "=========================\n",
      "Loss (train): 0.08161174345196799, Acc (train): 0.9811930098432176\n",
      "Loss (val): 5.79871407696298, Acc (val): 0.5114877163224919\n",
      "CPU times: user 35min 41s, sys: 3.45 s, total: 35min 44s\n",
      "Wall time: 6min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    running_loss = .0\n",
    "    running_acc = .0\n",
    "    best_acc = .0\n",
    "    best_model = None\n",
    "    print(f\"\\nEpoch {epoch}/{EPOCHS}\\n{'='*25}\")\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train': model.train()\n",
    "        if phase == 'val': model.eval()\n",
    "        for inputs, targets in loaders[phase]:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            accuracy = (torch.argmax(outputs, dim=1) == targets).float().mean()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_acc += accuracy.item()\n",
    "        if phase == 'val' and accuracy > best_acc:\n",
    "            best_acc = accuracy\n",
    "            best_model = deepcopy(model.state_dict())\n",
    "        print(f\"Loss ({phase}): {running_loss/len(loaders[phase])}, Acc ({phase}): {running_acc/len(loaders[phase])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model, 'foodnet.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
